{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ae91f21-c760-42e2-8d03-83f2253d5b67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\n",
    "    \"fs.azure.account.key.projectnf.dfs.core.windows.net\",\n",
    "  \"ntzj8hOFCbU6O7L069dR4Bxqnb/uE8v9STC+eqHFitEANjJpSskZE0oW9GI6o3xr0TP5AOagZb0P+AStupAZ8g==\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa5ba3c7-5ee3-4967-b8db-71e29850e267",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+--------------------+-----+-----------+\n| filename|label|                path| size|label_index|\n+---------+-----+--------------------+-----+-----------+\n|1 no.jpeg|   no|abfss://lakehouse...|54521|          0|\n|10 no.jpg|   no|abfss://lakehouse...| 3848|          0|\n|11 no.jpg|   no|abfss://lakehouse...| 3475|          0|\n|12 no.jpg|   no|abfss://lakehouse...| 4142|          0|\n|13 no.jpg|   no|abfss://lakehouse...| 4570|          0|\n+---------+-----+--------------------+-----+-----------+\nonly showing top 5 rows\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.format(\"delta\").load(\n",
    "    \"abfss://lakehouse@projectnf.dfs.core.windows.net/gold/brain_metadata_clean/\"\n",
    ")\n",
    "\n",
    "df.show(5)\n",
    "df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62edd2c2-df4b-4e66-978a-d14d518180a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-------------+-----------+-----------+\n|filename| size|      size_kb|size_bucket|label_index|\n+--------+-----+-------------+-----------+-----------+\n| Y52.jpg|61240|   59.8046875|     medium|          1|\n| Y53.jpg| 5011| 4.8935546875|      small|          1|\n| Y54.jpg|15874| 15.501953125|      small|          1|\n| Y55.jpg|43087|42.0771484375|      small|          1|\n| Y56.jpg| 7633| 7.4541015625|      small|          1|\n| Y58.JPG|21237|20.7392578125|      small|          1|\n| Y59.JPG|17890| 17.470703125|      small|          1|\n|  Y6.jpg|86579|84.5498046875|     medium|          1|\n| Y60.jpg| 7400|    7.2265625|      small|          1|\n| Y61.jpg|65584|    64.046875|     medium|          1|\n+--------+-----+-------------+-----------+-----------+\nonly showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# start from your clean df\n",
    "df_feats = df.withColumn(\"size_kb\", (col(\"size\") / 1024.0))\n",
    "\n",
    "df_feats = df_feats.withColumn(\n",
    "    \"size_bucket\",\n",
    "    when(col(\"size_kb\") < 50,  \"small\")\n",
    "     .when(col(\"size_kb\") < 150, \"medium\")\n",
    "     .otherwise(\"large\")\n",
    ")\n",
    "\n",
    "df_feats.select(\"filename\", \"size\", \"size_kb\", \"size_bucket\", \"label_index\").show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7051c9f-29f7-4093-ac51-0f767a39e795",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(361, 60, 85)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df, test_df = df_feats.randomSplit([0.7, 0.15, 0.15], seed=42)\n",
    "\n",
    "train_df.count(), val_df.count(), test_df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53166f09-f21f-4143-a8e0-80313e1287ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base = \"abfss://lakehouse@projectnf.dfs.core.windows.net/gold/brain_features_v1\"\n",
    "\n",
    "train_df.write.format(\"delta\").mode(\"overwrite\").save(base + \"/train\")\n",
    "val_df.write.format(\"delta\").mode(\"overwrite\").save(base + \"/val\")\n",
    "test_df.write.format(\"delta\").mode(\"overwrite\").save(base + \"/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8e15533-b814-4475-b92c-7a9170b3b294",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 361\nVal rows  : 60\nTest rows : 85\n+---------+-----+--------------------+----+-----------+------------+-----------+\n| filename|label|                path|size|label_index|     size_kb|size_bucket|\n+---------+-----+--------------------+----+-----------+------------+-----------+\n|35 no.jpg|   no|abfss://lakehouse...|6021|          0|5.8798828125|      small|\n|37 no.jpg|   no|abfss://lakehouse...|6770|          0| 6.611328125|      small|\n|38 no.jpg|   no|abfss://lakehouse...|7371|          0|7.1982421875|      small|\n|40 no.jpg|   no|abfss://lakehouse...|5758|          0| 5.623046875|      small|\n|41 no.jpg|   no|abfss://lakehouse...|5758|          0| 5.623046875|      small|\n+---------+-----+--------------------+----+-----------+------------+-----------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "train = spark.read.format(\"delta\").load(base + \"/train\")\n",
    "val   = spark.read.format(\"delta\").load(base + \"/val\")\n",
    "test  = spark.read.format(\"delta\").load(base + \"/test\")\n",
    "\n",
    "print(\"Train rows:\", train.count())\n",
    "print(\"Val rows  :\", val.count())\n",
    "print(\"Test rows :\", test.count())\n",
    "\n",
    "train.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae873fd6-5938-4312-9ce9-6bfc293cf6c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class counts:\n+-----------+-----+\n|label_index|count|\n+-----------+-----+\n|          1|  223|\n|          0|  138|\n+-----------+-----+\n\nVal class counts:\n+-----------+-----+\n|label_index|count|\n+-----------+-----+\n|          1|   34|\n|          0|   26|\n+-----------+-----+\n\nTest class counts:\n+-----------+-----+\n|label_index|count|\n+-----------+-----+\n|          1|   53|\n|          0|   32|\n+-----------+-----+\n\nTrain size_bucket distribution:\n+-----------+-----+\n|size_bucket|count|\n+-----------+-----+\n|     medium|   46|\n|      small|  300|\n|      large|   15|\n+-----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "print(\"Train class counts:\")\n",
    "train.groupBy(\"label_index\").count().show()\n",
    "\n",
    "print(\"Val class counts:\")\n",
    "val.groupBy(\"label_index\").count().show()\n",
    "\n",
    "print(\"Test class counts:\")\n",
    "test.groupBy(\"label_index\").count().show()\n",
    "\n",
    "# Optional: size bucket distribution\n",
    "print(\"Train size_bucket distribution:\")\n",
    "train.groupBy(\"size_bucket\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f65e83f-6261-4e21-b760-dbba2adf50a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n|label_index|count|\n+-----------+-----+\n|          1|  223|\n|          0|  138|\n+-----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "train.count(), val.count(), test.count()\n",
    "train.groupBy(\"label_index\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a180c974-5ac9-4e16-a0a4-479303d2a9a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base = \"abfss://lakehouse@projectnf.dfs.core.windows.net/gold/brain_features_v1\"\n",
    "\n",
    "train = spark.read.format(\"delta\").load(base + \"/train\")\n",
    "val   = spark.read.format(\"delta\").load(base + \"/val\")\n",
    "test  = spark.read.format(\"delta\").load(base + \"/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "546543ec-e7f1-49a5-83cf-2d0923972fa2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "threshold = 10.0  \n",
    "\n",
    "train_pred = train.withColumn(\n",
    "    \"prediction\",\n",
    "    when(col(\"size_kb\") > threshold, 1).otherwise(0)\n",
    ")\n",
    "\n",
    "val_pred = val.withColumn(\n",
    "    \"prediction\",\n",
    "    when(col(\"size_kb\") > threshold, 1).otherwise(0)\n",
    ")\n",
    "\n",
    "test_pred = test.withColumn(\n",
    "    \"prediction\",\n",
    "    when(col(\"size_kb\") > threshold, 1).otherwise(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49acc03c-7547-4ec1-b33f-bdd8241f520a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-----+\n|label_index|prediction|count|\n+-----------+----------+-----+\n|          1|         0|    2|\n|          1|         1|   32|\n|          0|         0|   12|\n|          0|         1|   14|\n+-----------+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "val_pred.groupBy(\"label_index\", \"prediction\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "408428c0-e2bf-496d-8d13-7a699f1249fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.7333333333333333, 0.6956521739130435, 0.9411764705882353)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = val_pred.filter(\"prediction = 1 AND label_index = 1\").count()\n",
    "tn = val_pred.filter(\"prediction = 0 AND label_index = 0\").count()\n",
    "fp = val_pred.filter(\"prediction = 1 AND label_index = 0\").count()\n",
    "fn = val_pred.filter(\"prediction = 0 AND label_index = 1\").count()\n",
    "\n",
    "total = val_pred.count()\n",
    "\n",
    "accuracy  = (tp + tn) / total if total > 0 else 0\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall    = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "accuracy, precision, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12c7d9d3-9e81-43a8-8550-1df9cadff27b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "best_threshold = 10.0\n",
    "\n",
    "def predict_tumor(size_kb):\n",
    "    return 1 if size_kb > best_threshold else 0\n",
    "\n",
    "predict_udf = udf(predict_tumor, IntegerType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a64eb66e-b98a-435d-90ad-fd5bcee90824",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------------------+-----+-----------+-------------+-----------+----------+\n|filename|label|                path| size|label_index|      size_kb|size_bucket|prediction|\n+--------+-----+--------------------+-----+-----------+-------------+-----------+----------+\n|Y106.jpg|  yes|abfss://lakehouse...| 6155|          1| 6.0107421875|      small|         0|\n|Y111.JPG|  yes|abfss://lakehouse...|25806|          1| 25.201171875|      small|         1|\n|Y120.JPG|  yes|abfss://lakehouse...|15723|          1|15.3544921875|      small|         1|\n|Y146.JPG|  yes|abfss://lakehouse...|24840|          1|   24.2578125|      small|         1|\n|Y147.JPG|  yes|abfss://lakehouse...|28150|          1| 27.490234375|      small|         1|\n| Y15.jpg|  yes|abfss://lakehouse...|17045|          1|16.6455078125|      small|         1|\n|Y159.JPG|  yes|abfss://lakehouse...|22534|          1| 22.005859375|      small|         1|\n|Y164.JPG|  yes|abfss://lakehouse...|17907|          1|17.4873046875|      small|         1|\n| Y17.jpg|  yes|abfss://lakehouse...|30267|          1|29.5576171875|      small|         1|\n|Y170.JPG|  yes|abfss://lakehouse...|26219|          1|25.6044921875|      small|         1|\n+--------+-----+--------------------+-----+-----------+-------------+-----------+----------+\nonly showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "deployed_test = test.withColumn(\"prediction\", predict_udf(col(\"size_kb\")))\n",
    "deployed_test.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9f50f33-ac6c-4c2e-be86-3f43706f199c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.6823529411764706, 0.7321428571428571, 0.7735849056603774)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def metrics(df):\n",
    "    tp = df.filter(\"prediction = 1 AND label_index = 1\").count()\n",
    "    tn = df.filter(\"prediction = 0 AND label_index = 0\").count()\n",
    "    fp = df.filter(\"prediction = 1 AND label_index = 0\").count()\n",
    "    fn = df.filter(\"prediction = 0 AND label_index = 1\").count()\n",
    "\n",
    "    total = df.count()\n",
    "\n",
    "    accuracy  = (tp + tn) / total if total > 0 else 0\n",
    "    precision = tp / (tp + fp)   if (tp + fp) > 0 else 0\n",
    "    recall    = tp / (tp + fn)   if (tp + fn) > 0 else 0\n",
    "\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "metrics(deployed_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6821c01e-5e50-453b-99ef-faff0bf089d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n|prediction|count|\n+----------+-----+\n|         1|   56|\n|         0|   29|\n+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "deployed_test.groupBy(\"prediction\").count().show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "brain_feature_engineering",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}